{
  
    
        "post0": {
            "title": "Interpolating the internet",
            "content": "Large scale Deep Learning models can combine abstract concepts in new ways. GPT-3 can write stories while DALL¬∑E makes images. These models are improving fast so I want to explore what improved versions will do and how they will change the internet. . The best content generation today . The best AI content generators use large models trained on huge datasets. . These models work by storing all their training data in a ‚Äúlatent space‚Äù1. Think of this as a map where content is arranged by its properties (e.g. going left words get angrier, pictures become more cat like as you move up, etc). To create new content we can simply adjust our positions to get new combinations of properties. . . Unlike Google Search which stores links and searches for results, a deep learning model combines aspects of existing content to make new results. A great example of this is DALL¬∑E which works like Google image search on steroids, interpolating between relevent results rather than indexing them. . Both are results for the prompt ‚Äúa road sign with an image of a blue strawberry‚Äù: . . . Notice that Google‚Äôs results are not relevent. It is perfectly plausible for their to be ‚Äúa road sign with an image of a blue strawberry‚Äù but there aren‚Äôt many on the internet. . Meanwhile every one of DALL¬∑E‚Äôs generations are relevent. Of course producing these outputs currently takes a long time and is expensive but this tech is scaling fast. . A similar phenomenon is playing out with text. . GPT-3 is trained to complete text prompts. Here ideas and concepts can be merged to reason &amp; write stories like in this hilarious example: . I am so, so sorry. I could not resist adding a single sentence and watching this beautiful meeting between Alan Turing and Claude Shannon descend into madness. pic.twitter.com/j0TXFPKyZE . &mdash; Jonathan Fly üëæ (@jonathanfly) July 17, 2020 Already people are generating articles using GPT-3 by giving manual prompts. . It is important to keep in mind that GPT-3 and DALL¬∑E are almost the same model. They both use a large transformer with DALL¬∑E using a VQ-VAE to compress images into token-like sequences. You can think of this as a learned compiler for images with GPT-3 acting as the programmer. . This means we can apply the DALL¬∑E format {content search query} {VQ-VAE tokens} to any form of data. Expect VQ-VAEs to allow a future GPT model to generate any form of content letting it generate full rendered web pages rather then just text. . How will these models improve? . The large datasets training these models are the same ones used by search engines. . When we search today we hope someone has made something just like what we‚Äôre looking fo. With a large scale deep learning model that won‚Äôt be the case. . Instead a search could query a large model thats interpolates between the best results to find that image, article, video, etc that exactly matches your query. . Once these ‚ÄúGenerators‚Äù become mainstream we‚Äôre going to have to change our perspective on what the internet is. . We will no longer think of something being on or off the internet. The idea that someone has their ‚Äúnudes posted online‚Äù will be a meaningless phrase as you will inevitably generate nudes as you search for them. . The only value in ‚Äúmaking‚Äù images will be in finding the right one, to search latent space to best fulfil someones needs. . Most content will be generated on demand to a users needs but some will be automated, expect Spotify &amp; YouTube to take full advantage of their huge datasets to create content. . Having these generators will feel imensly powerful, finaly I‚Äôll get to make a water bending VR game, the amount of content posted online will tenfold! . Eventually a new internet will emerge. One where rather than searching for a peice of content hand-made by a person, all content is generated to suit our individual needs. This will feel like we each have our own internet. One where all content matches just what we want. . What you can do now. . If we are on the cusp of a new Google how can you take advantage of this? The best thing to do is get involved on early AI content generation tools. Some of these are completely autonomous and some require a human in the loop. Here are some ideas I‚Äôve been considering. . Transformer-VAEs as a search engine . To make a new Google your probably going to need a Transformer-VAE. . I‚Äôve just released a project that allows using the transformer to interpolate over text and small images. Hopefully once I try training at scale I‚Äôll be able to interpolate over entire documents. . Once it can interpolate over entire documents why not use it with a search engine to interpolate between the top results to best match a query? . Auto ArtBreeder . ArtBreeder uses a mix of VAE‚Äôs &amp; GAN‚Äôs to generate images by combining latent variables of existing images to interpolate between them. Images are interpolated several times over to generate novel and strickingly different images. . This is different to most content generators in that you can‚Äôt see an output image and easily know how to find it in latent space. In the future algorithms will be needed to discover new images in these spaces (see Kenith Stanley‚Äôs interview for more info). Perhaps processing interpolated images with OpenAI‚Äôs new CLIP model will allow discovering new images? . The final result would allow for fully automanus brainstorming. Use this to prompt a larger model and you could get some compelling &amp; creative outputs. . Other Ideas . These ideas work great for very flexible mediums like images and text where slight mstakes can go unnoticed. . Could some clever fixes allow applying them to strict domains like program synthesis? Maybe you could use latent variables to add/remove concepts in a Python function? . Footnotes . Since these models are trained with gradient descent they approximate non-parametric models (a.k.a. models that reason from their dataset rather than learning programs) see more here.¬†&#8617; . |",
            "url": "https://fraser-greenlee.github.io/ml/2021/03/11/Interpolating-the-internet.html",
            "relUrl": "/ml/2021/03/11/Interpolating-the-internet.html",
            "date": " ‚Ä¢ Mar 11, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Improved Transformer-VAE",
            "content": ". I have made an improved Transformer-VAE that gives much more compelling interpolations on a wider range of tasks than my previous work T5-VAE. You can try out training in Colab or check out the source code. . In this post I‚Äôll describe the changes I made and what this has taught me about independent ML research. . Motivation | Baselines | Improvements | Changes that didn‚Äôt work out. | Conculsion | Motivation . As outlined in a previous post I think large transformer VAEs have a lot of potential. . They let you interpolate between pieces of data (text, images, etc) to find new and plausible combinations. By interpolating between data points we can make machines creative. . Transformers are the most general type of neural network, able to get top results in images &amp; text with few priors on the data. This means a large scale Transformer-VAE will be able to create better interpolations than any other architecture. . With this in mind I set out to improve on my initial Transformer VAE. . Baselines . To test performance I opted to judge the model on interpolation quality and how semantically organised the latent codes are. . To check the semantic organisation of the latent codes I used a news headlines dataset and trained an SVM on the latent codes to predict the news headline category. . For interpolation quality I looked at syntactic &amp; semantic correctness. Here I define syntax as a strict set of rules that all samples must follow (like those of a compiler), for semantics I mean that samples qualitatively appear to be a mix between one sample and the other. . The syntax test used this python lines dataset and interpolations were tested for syntax errors. For semantics I trained the model to recreate MNIST characters using this dataset and looked to see if the character mixes were credible. . Improvements . Firstly I‚Äôve swapped out the T5-encoder for the Funnel transformer encoder (though still using the shared T5 embeddings). The Funnel transformer is trained to compress sequence data so it doesn‚Äôt have to use as many parameters to produce encodings. . Then I treat each funnel token as its own seperate latent code, this gives me more latent codes to use in the MMD loss. This gives me more tokens to regularise which is important when the total batch size is low. . When creating the reconstructed encoding I use LayerNorm on the reconstructed tokens to match the Funnel encoder. . For handling large sequences I added gradient checkpointing and a basic window attention mechanism. . Gradient checkpointing simply ignores the gradients for most layers and recalculates then when backpropagating. This can greatly help save memory and approximates the reversible layers of the Reformer which doesn‚Äôt have cross-attention. . Window attention only handles operates on subsequences of the data of length widow size. Here I just feed each decoder layer subsequences of the data that overlap between layers. In the future I could replace the self-attention layers with a Longformer self-attention followed by T5 cross attention on subsequences. . Changes that didn‚Äôt work out. . The key idea with Transformer-VAE is that by using a large transformer we can get a consistently valid output regardless of the latent code. Currently interpolation performance doesn‚Äôt clearly improve as the model gets more accurate. I measure this by learning lines of Python code and measuring how often interpolations have syntax errors. . Here are some samples from my best traininig run (note that auto-encoding accuracy is 89% all logs): . # ratio sequence valid 0 start_timeperiod = prev_timeperiod T 0.1 start_timeperiod = prev_timeperiod T 0.2 start_timeperiod = prev_timeperiod T 0.3 start_timeperiod = prev_timeperiod T 0.4 start_timeperios = prev_Infood T 0.5 return_qualos = min(vlabo) T 0.6 return summary_stats = min(balance)) False 0.7 return summary_stats(balance)) False 0.8 return summary_stats(balance)) False 0.9 return summary_stats(balance)) False 1 return summary_stats(balance)) False 0 raise ValueError(&#39;Infinite observation encountered.&#39;) T 0.1 raise ValueError(&#39;Infinite observation encountered.&#39;) T 0.2 raise ValueError(&#39;Infinite observation encountered.&#39;) T 0.3 raise ValueError(&#39;Infinite observation encountered.&#39;) T 0.4 raise outError(&#39; prefinite observation_type&#39;.&#39;) False 0.5 raise out(&#39;lert_typeREN_type&#39;.) False 0.6 global outdir_type_type._type False 0.7 global outdir_type_type T 0.8 global outdir_type_type T 0.9 global outdir_type_type T 1 global outdir_type_ T . Overall ~65% of interpolation points were valid. Note that I did not use a Python specific tokenizer which means that some tokens will make syntax errors more likely. One potential way to improve this is to optimize the interpolations directly. . I tried 3 methods of doing this, none substantially changed performance. . Critic loss had another funnel encoder operate on the final decoder hidden state to predict the interpolation ratio (inspired by the adviserial interpolations paper). The critic was accurate but it didn‚Äôt improve the model. . Cycle loss put a cosine embedding loss on latent VS Encoder(Decoder( latent )). This is to encourage the latent space to become a bijective mapping. . Lastly I tried adding a smoothness loss where the gradient of the logits w.r.t the interpolation ratio was minimized. . Both of the above methods were inspired by this paper. . Unfortunately I didn‚Äôt learn a great deal from these methods, they just didn‚Äôt update the model that much or lowered performance. This is likely because these methods were original applied to image models where the data is less discrete. Current SOTA for training text transformers with an adversary is by using reinforcement learning which I wanted to stay away from as it would necessitate longer training times. . Conculsion . Overall this project took wayyy longer than I expected. In the future I‚Äôm going to try to work more incrementally, making small, test-able experiments at a time. . Tips for your own research side project: . Remember that choosing the right thing to work on is more important than running experiments and writing code. | Start by setting up a small test of your hypothesis, this should be a baseline with a performance metric. | Stay small, reuse open-source code &amp; data where possible and do fast runs on Google Colab. | Lean on the side of caution when trying out a new method. Read related papers where possible so you can skip on less promising ideas. | . If you want to see even more results you can check out this Weights and Biasis report. I hope to release some cool demos using this project soon! If you want to help out feel free to reach out to @FraserGreenlee. . There is a ton of ideas yet to be explored using this project! . What would an ArtBreeder of sequences be like? Could it create compelling writing prompts via interpolation? | Can semantic directions in latent space be found so you can edit texts at a high level? | Does part of the latent codes encode style? If so can that style be applied to other sequences? | The model has a prior on the distribution of latent codes, could that be replaced by a more general loss? | I was keen on smooth latent codes as I hoped to take advantage of their differentiability. Now discrete VQ-VAEs are shown to achieve great results why not look into converting this project into one? | .",
            "url": "https://fraser-greenlee.github.io/ml/large%20prior-free%20models/transformer-vae/2021/02/23/An-Improved-Transformer-VAE.html",
            "relUrl": "/ml/large%20prior-free%20models/transformer-vae/2021/02/23/An-Improved-Transformer-VAE.html",
            "date": " ‚Ä¢ Feb 23, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Transformer-VAE for Program Synthesis",
            "content": "Motivation . Since releasing a Transformer Variational Autoencoder (T5-VAE) I have been looking into using it as a tool for reasoning. . I think learning compressed latent spaces is the only form of abstraction deep learning systems are capable of. I think reasoning using these latent codes will be key for future systems. . . T5-VAE reproduces sequences while compressing them into latent vectors with values between -1 and 1. Continuity between latent vectors is ensured, resulting in a semanticly organised space of sequences with each training sample corresponding to a position. Program synthesis involves creating a program to satisfy some input and output examples. To search efficiently intermediate programs need to be evaluated so only relevent areas are searched. This often involves scoring intermediate programs based on how close the output is to the correct one. The search space is then constrained to programs that increase said score. . If the programs were represented by positions in latent space and a deep learning model predicted the output state, we would have a loss (against the target output) to evaluate the program effectiveness and use Bayesian Optimisation to search the space. . To do this I‚Äôm developing a Python interpreter which uses T5-VAE‚Äôs to represent code and state named ‚ÄúLatent Executor‚Äù. Its currently in development but I‚Äôm excited to share what I‚Äôve learnt so far. . Architecture . The idea is to learn a semanticly organised map of code and state just by looking at tokens. This means the model should learn to organise programing concepts making the resulting space easier to search! . To do This T5-VAEs are trained to represent code and state. Their resulting encodings are concatenated and given to what I‚Äôm calling an executor which is a T5-encoder which maps the (state + code) encoding into the resulting state. This is then passed to the state autoencoder again to be decoded into the resulting state. . . Initial Tests . The first test for this model was to learn to find the missing value in simple sums. These were in the form 12+?=23 or 10+?=5. . Here ‚Äústate‚Äù represents the first value in the sum and the result (both being 2-digit positive integers) while ‚Äúcode‚Äù is the summed value (a 2-digit integer). . A small Latent Executor was made with T5-base encoders and decoders and a just 2 dimensional latent space. By only using 2 latent dimensions the space of ‚Äúprograms‚Äù was easy to visualise. . Here are the resulting state and code latent spaces. . . Even though the model just sees abstract tokens it has still grouped numbers with similar values. The code space looks better organised than the state space. This is caused by a bug resulting from passing the executor‚Äôs ‚ÄúEncoder Hidden‚Äù output back into the state autoencoder. T5-VAE is an MMD-VAE meaning it computes its regularisation loss using the maximal mean divergence between its latent codes in a given batch and a sample of latent codes from a normal distribution. I forgot to combine the latent codes produced by the executor and those produced by the autoencoder leading to 2 seperate distributions of latent codes trying to ocupy the same space, hence the hole when sampling from state strings. . A varient with a 10-dimensional latent space was also trained and by using t-SNE with multiple perplexities we can see a similar orginisation of state and code. Lower perplexities show local structure while high perplexities show global structure. . . . Since a continuous space of well organised code was found, it was time to try measuring the loss for different ‚Äúprograms‚Äù and check its accuracy. The loss used was state-decoder cross entropy which gave the most reliable signal. . . Looking at the loss, the lowest values (coloured white) are at or near -53. You can also see that the space is not perfectly organised, -50 and -51 are at oposite ends of the y-axis. If we were yo use gradient based optimisation (akin to rolling a ball down a hill) it would get stuck in one of the blue patches and likely not find the white patch at -53. This means gradient-based optimisation won‚Äôt be effective. . Another optimisation method seen in papers such as SD-VAE is bayesian optimisation with Gaussian Processes. Using it reliably finds solutions using latent codes with 2, 10 and 100 dimensions. . Next Steps . Although I‚Äôm excited to see it working here I want to extend this to handle multiple lines of code. This means using the executors output with another code encoding to send to the executor and produce a new state. That combined with a greater range of values should make a more interesting program synthesiser. .",
            "url": "https://fraser-greenlee.github.io/ml/large%20prior-free%20models/code/transformer-vae/2020/08/25/Transformer-VAE-for-Program-Synthesis.html",
            "relUrl": "/ml/large%20prior-free%20models/code/transformer-vae/2020/08/25/Transformer-VAE-for-Program-Synthesis.html",
            "date": " ‚Ä¢ Aug 25, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Transformers as Variational Autoencoders",
            "content": "Image generators based on Variational Autoencoders have had huge success. Unfortunately the same cannot be said for sequence generation. There seems to be little interest in this space but with Transformers it is now possible to learn smooth latent spaces of large structured sequences. . To show this I‚Äôm releasing T5-VAE a mod of Google‚Äôs Text-to-Text Transformer to learn smooth latent spaces of sequences. . Try using it in Google Colab. . See Weights &amp; Biasis training runs. . Check out the source code on GitHub. . From Autoencoders to MMD-VAE | A Transformer as an MMD-VAE | Use cases | From Autoencoders to MMD-VAE . To understand how this works and the ways it differs from previous systems, it is important to know how an autoencoder works, specifically a Maximum Mean Discrepancy Variational Autoencoder. . . An Autoencoder learns to recreate its training data by compressing the data into a compressed representation called a ‚Äúlatent code‚Äù and decompressing it back into the original data. Each latent code is just a vector of numbers with each number constrained within some bounds (between -1, 1 in this case by a Tanh function). You can think of each latent vector as a position on a latent map of input data. In each direction on the map our input data changes in semantic ways. . The problem with an Autoencoder is that our latent map has holes. These holes are where latent codes have no set meaning and so result in garbage output from the decoder. To resolve this we use a Variational Autoencoder (VAE). It has a regularising loss function which encourages a smooth distribution of latent codes. This regularising loss encourages our latent codes to match a target probability distribution, usually a bell curve. Now intermediate points on our map are also valid points meaning we can traverse it smoothly. . Unfortunately, when applying this model to sequences it doesn‚Äôt work. The issue comes from our extra loss function and how we decode sequences. . Our regularising loss encourages the latent space to be smoother but if the loss is brought to near zero the space becomes meaningless. This is tempered by the reconstruction loss which encourages the latent space to be informative. If the decoder is generating a sequence, it has access to the previous tokens in its current sequence which during training are always correct. When the decoder has the option of a slightly random latent code or a nonrandom previous output it ignores the latent code &amp; just looks at its previous tokens. . This is known as ‚Äúposterior collapse‚Äù since the posterior is the probability of an event (the next token) given relevant information (the latent code). The resulting model ignores the latent code and so just models a prior distribution of tokens. . To solve this the Maximum Mean Discrepancy Variational Autoencoder was made. It is similar to a VAE but instead of the reconstruction loss, it uses an MMD (mean-maximum-discrepancy) loss. The MMD loss measures the similarity between latent codes, between samples from the target distribution and between both latent codes &amp; samples. It optimises the similarity between latent codes &amp; target samples separately to match the similarity between mixed samples. . This loss is much softer on the latest codes and solved posterior collapse for my use case. If your keen to learn more about MMD-VAE you should check out this post. . A Transformer as an MMD-VAE . Lets put this model to use to generate some structured sequences. The T5 model provided by Huggingface will create the Encoder &amp; Decoder for the sequences. To get a compressed encoding of the inputs, the inputs are first padded to ensure each the sequence is 12 tokens long. Finally, some fully-connected layers compress and then decompress the fixed length encodings. I‚Äôve named this model ‚ÄúT5-VAE‚Äù. . . This model is then trained to recreate its input tokens with the MMD loss on its latent code. Once training is complete it is possible to start generating some sequences! . I tried out recreating single lines of code from my dataset of 9 million Python state changes. This code comes from real coding solutions so the model will learn more useful snippets of code than if the data was random. However, this also means the code snippets could be more varied. . Here I step through the latent space between 2 sample code snippets. . # Intermediate Samples 0.0 x = a - 1; # Starting latent space 0.1 x = a - 1; 0.2 x = a - 1; 0.3 x = a - 1; 0.4 x = a + 1; 0.5 x = a + 2; 0.6 x = a + 2; 0.7 x = a + 2 * 2; 0.8 x = a + 10 * 2; 0.9 x = a + 10 * 2; 1.0 x = a + 10 * 2; # Ending latent space . Here I randomly generate latent codes to see how common syntax errors are. . # Randomly Sampled Sequences er = int(h[3] * 0); l.append([False[j] * d); # Invalid Code y = &#39;[0 &#39;] = 1; # Invalid Code x = int(h[-1] * 0); l.append( = 0 + str(x[0 / 1]); # Invalid Code x.append(a[da] * 0); x =&#39;&#39;[0 - 1:0]; x.append(x.pop( + 1) ** 0); f = int(h[i].pop() + 1); x = int(h[-1 - 1]); . Though the intermediate values are good, just randomly sampling from the latent space occasionally produces invalid outputs. . Use cases . Now that we can learn smooth latent spaces of sequences a lot is possible: . Learn a position in latent space . Train another model take T5-VAE encodings (e.g. representing a tweet) and predict some property (e.g. the number of likes). Now you can get a loss based on your target number of likes and backpropagate that loss to change the latent position of a given tweet. The result should be a tweet optimizer! I‚Äôve got a demo of this coming soon. | . | Discover semantic changes in latent space . Change a sequence in one way (e.g. change the tone) and find the difference in latent space. You may be able to apply that change in latent space to other sequences to get a tone changer. | . | .",
            "url": "https://fraser-greenlee.github.io/ml/large%20prior-free%20models/transformer-vae/2020/08/13/Transformers-as-Variational-Autoencoders.html",
            "relUrl": "/ml/large%20prior-free%20models/transformer-vae/2020/08/13/Transformers-as-Variational-Autoencoders.html",
            "date": " ‚Ä¢ Aug 13, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Avatar game with realistic physics",
            "content": "After watching Avatar: The Last Airbender I wanted to experience bending the elements just like in the show. Of course actually doing this is impossible but could a game give that feeling? . . It turns out that you can achieve a compelling water bendning effect using Unity! Here‚Äôs the end result. . Water bendings looking smooth now.Anyone got tips on making art assets? Hoping to get an ATLA feel. pic.twitter.com/CbdPFY8SSv . &mdash; Fraser (@FraserGreenlee) August 16, 2020 So how did I do this? . Before jumping into 3D lets consider the problem in just 2 dimensions. Corona Labs lets you make 2D cross-platform games and it comes with a realistic particle simulator. . It comes with this demo below, click below to try it! . This gives some interaction with particles but doesn‚Äôt create the smooth flows of water you see in the show. . It works by making all particles within the orange box match the box‚Äôs velocity. This is done by repeatedly running queryRegion which sets particle velocity in a given region. Notably this allows incrimenting particle velocity as well. . Lets picture the first GIF but with imagined forces on the water drawn as arrows. . . Now to get a bending effect we can recreate the above GIF it with multiple queryRegion boxes. . Using the grid above, when a user taps the screen a ring of cells are updated with each pointing to the cursor. To ensure the cursor is always in the middle of a grid cell the whole grid is shifted as the cursor moves between cells. . For cell values I make the magnitude‚Äôs greater for further out cells as I found this better holds the particles together. To get long streams of water I gradually decrease old cell values. . Below I show the cell values with white arrows (longer for greator velocity incriments). . Try water bending below. . Then by making particles with different physical properties you get different materials. Ice is a solid group of particles, green acid mixes colour with the blue water, slime is a sticky group of particles while mud is viscous. . Checkout the 2D source here. . 3D bending . Now that our 2D bending is pretty cool we‚Äôve just got to extend it into 3D! . First we can use ObiFluids to simulate particles in 3D. Sadly it doesn‚Äôt come with a native queryRegion method but we can just make one by partitioning space into a 3D grid. . When running the code iterates over every particle to find its region &amp; adjusts the velocity in the same way as before. . This could clearly make a compelling VR game, unfortunatley I am too invested in an ML project right now to do more work. If you would like any other implementation details feel free to reach out to me on Twitter. . Water bendings looking smooth now.Anyone got tips on making art assets? Hoping to get an ATLA feel. pic.twitter.com/CbdPFY8SSv . &mdash; Fraser (@FraserGreenlee) August 16, 2020",
            "url": "https://fraser-greenlee.github.io/games/simulation/2020/07/08/An-Avatar-game-with-realistic-physics.html",
            "relUrl": "/games/simulation/2020/07/08/An-Avatar-game-with-realistic-physics.html",
            "date": " ‚Ä¢ Jul 8, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "A dataset of ran code",
            "content": "Existing ML for code methods often learn from raw source code and sometimes use data flow to understand programs. While these offer large amounts of data they don‚Äôt actually show what code fundamentally does, changes state. . With that in mind I‚Äôve created a dataset of over 1 million ran python programming solutions with state changes shown after each line of code. Get it here . Motivation An example | | How I got this data Recording State Changes | | Initial Results Pre-Training | A Downstream Task | | Future Work | Motivation . Most AI for code models only learn from reading code. This lets AI models recognise patterns in the code &amp; generate sensible-looking code. . But do these models really understand code? If you were to read code without running anything and had no prior knowledge of programming would you know how to use it? . An example . Lets try learning about a single program character the way an AI would. . Below is a simple program with just 1 character replaced by a Chinese character making the code inscrutable. This is a similar experience for an AI seeing the true character for the first time. . As you can see the code is inscrutable. . C = AÂÖ≠B D = BÂÖ≠C E = AÂÖ≠D D = CÂÖ≠E . How could I make this understandable without showing the true character? . Since all code does is change state, lets show state changes between each line. . Below shows state changes but the values are also represented by Chinese characters. . .. A = ‰π¶ .. B = Êõ∏ C = AÂÖ≠B .. C = Êõ∏ D = BÂÖ≠C .. D = ‰π¶ E = AÂÖ≠D .. E = ‰π¶ D = CÂÖ≠E .. D = Êõ∏ . Lets look at all the operations with the values substituted in: . ‰π¶ÂÖ≠Êõ∏=Êõ∏, Êõ∏ÂÖ≠Êõ∏=‰π¶, ‰π¶ÂÖ≠‰π¶=‰π¶, Êõ∏ÂÖ≠‰π¶=Êõ∏ . If you are familiar with programming you may be able to guess that ÂÖ≠ is an and operator with ‰π¶ being True &amp; Êõ∏ being False. . Here‚Äôs the original code with swapped words: . # and is ÂÖ≠ # True is ‰π¶ # False is Êõ∏ C = A and B A = A and C D = C and B D = D and D . Think how much more code you would need to read to figure out what ÂÖ≠ meant if you couldn‚Äôt see state changes. For this reason I rekon showing state changes will help AI models understand code. . How I got this data . I first found the CodeChef dataset it‚Äôs got 1 million solutions to programming problems but few are in Python and many aren‚Äôt runnable. . HackerRank is a site where programmers can practice for interviews on their huge range of programming problems. It has a ‚ÄúSee Solutions‚Äù button that lets you read other peoples solutions. I used Selenium to click on that button for every problem to get solution URLs. Then I used Requests to download those solutions. After a few days I had 1 million solution code snippets with on average 1k solutions per problem. . Recording State Changes . Once I had my runnable code snippets I used Snoop to record all the state changes occurring in each program run. . Snoop dynamically adds logs to your code showing what has executed &amp; which state values have changed. To see how this works check out this talk. . . Next step was to run all the code snippets. The script used to run the code and progress logs can be found here. Thankfully running all these code snippets didn‚Äôt cause many issues, I just had to watch out for some the occasional massive code snippet. . An interesting yet worrying feature of the Snoop files is that they are highly compressible, the zip file is 1/10th the size of the txt file. This is likely due to repetitions in the snoop due to the same code being ran repeatedly in for loops and method calls. . Initial Results . With the dataset completed I trained gpt2 to perform causal language modelling on the raw text. I wanted to see if the Snoops text offers the model any unique insights about code. . Pre-Training . Here you can see some initial results on training gpt2 &amp; BERT on the data. . . Surprisingly gpt2 with OpenAI pre-training (blue) is actually already very accurate on the Snoop text. . When having it generate text with short prompts I found it to be far less accurate than the 1.1 evaluation perplexity. It seems like the gpt2 model is spotting patterns in it‚Äôs prefix string &amp; is using them to predict future tokens rather than having a probabilistic model of an interpreter. . A Downstream Task . Here you can see it fine-tuned on CoNaLa (a description-to-code translation task). The Snoop data is better than no pre-training but not as good as gpt2 with OpenAI pre-training. Of course the Snoops model hasn‚Äôt had the same amount of training time nor has it seen natural language before so its not a fair test. . . . Future Work . There‚Äôs a lot of potential in using state changes to understand code. Right now I don‚Äôt think just reading the raw snoops text is the way to go but I think a well formatted, compressed version could do better. Next time I‚Äôll show how well a compressed version of this dataset can teach a transformer to act as a Python interpreter. . Here‚Äôs some other investigations you could do with this dataset: . Further testing on how this helps downstream tasks, try training a language model on just the code &amp; just the Snoop, see which does better on downstream tasks &amp; by how much. These downstream tasks could include bug detection, data type prediction, search &amp; description2code generation. | Run Snoop on the Django source code with the English2Django dataset comments in the code. That way a language model will learn NLP, code &amp; state all at the same time. Note that I got a lot of STATE_UNAVAILABLE messages when I tried this so be ready to filter a lot of data. | Try applying this method to another programming language, maybe there‚Äôs a similar tool for Java or Javascript? | Try filtering &amp; rearranging the data for new tasks. It offers a valuable insight as to what parts of the source code are useful to humans. | .",
            "url": "https://fraser-greenlee.github.io/ml/datasets/code/2020/06/25/a-dataset-of-ran-code.html",
            "relUrl": "/ml/datasets/code/2020/06/25/a-dataset-of-ran-code.html",
            "date": " ‚Ä¢ Jun 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I‚Äôm a software Engineer at Darktrace doing ML research in my spare time. . Checkout my CV .",
          "url": "https://fraser-greenlee.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://fraser-greenlee.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}